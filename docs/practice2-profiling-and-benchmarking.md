# Практика 2: Профилирование и бенчмаркинг

## Цели

__Цель данной работы__ — познакомиться с source-level подходом к профилированию,
практикой написания тестов на производительность, их запуска и анализа метрик
производительности. В результате выполнения практического задания должно
сформироваться общее представление о поиске узких мест в приложении и процессе
бенчмаркинга, в данном случае понимаемого как регрессионное тестирование
производительности.

## Задачи

  1. Проанализировать время работы фильтра скелетонизации, понять сколько
     времени потребляет каждая из функций. Определить самые медленные функции,
     которые требуют оптимизации.
  1. Реализовать набор тестов на производительность. В первую очередь должны
     тестироваться сценарии, похожие на тот, который возникает в
     демо-приложении. Это важно, поскольку именно их мы впоследствии будем
     оптимизировать. Кроме того, следует добавить и другие тесты на
     производительноть.
  1. Собрать несколько отчетов с метриками по производительности. В частности,
     можно проанализировать, насколько замедляет приложение сохранение
     изображений и замеры времени. Построить сравнительный отчет.

## Общая последовательность действий

  1. Инструментируем функцию `skeletonize` замерами времени (макросы `TS` и
     `TE`). Запускаем демо-приложение и анализируем время работы каждого шага.
     Проверяем, что сумма шагов примерно равна общему времени работы приложения.
  1. Прежде чем учиться писать тесты, стоит научиться их запускать и
     анализировать собранные метрики. Для этого запускаем сборку `perf_skeleton`
     с опцией сохранения XML-отчета. Затем анализируем метрики при помощи
     скриптов из OpenCV (`summary.py`, `report.py`). Детальные инструкции можно
     найти [здесь][using-perf-tests]. Также полезно сохранить несколько отчетов,
     и сравнить их друг с другом. Разброс значений стоит сопоставить с тем, что
     мы наблюдали при запуске демо-приложения.
  1. Далее пишем тест производительности на функцию `skeletonize`. Это делается
     в файле `perf/perf_skeleton`. Инструкции можно посмотреть в
     [документации][writing-perf-tests] к OpenCV. Проверяем, что время работы
     теста примерно равно тому времени, которое мы видели в консоли. Если
     имеются существенные различия, стараемся добиться похожих результатов,
     как правило разница в параметрах вызова функций.
  1. В качестве последнего шага стоит реализовать тесты производительности на
     три основных шага алгоритма: функции `ConvertColor_BGR2GRAY_BT709`,
     `ImageResize` и `GuoHallThinning`. Здесь также необходимо имитировать
     сценарий использования, аналогичный тому, что был в демо-приложении, чтобы
     получить похожие времена работы. Именно эти тесты впоследствии должны
     использоваться для анализа ваших ускорений.

## Детальная инструкция по выполнению работы

### Профилирование

  1. Прежде чем приступить к выполнению практической работы, рекомендуется
     получить свежие версии файлов из центрального репозитория. Это обычный шаг,
     с этого как правило начинают день программисты. И мы сразу же создаем новую
     ветку для выполнения второго практического задания.

     ```bash
     $ cd <itseez-ws-2016-practice>
     $ git checkout master
     $ git pull origin master
     $ git checkout -b profiling-and-benchmarking
     ```

  1. Далее нужно выполнить инструментировать функцию `skeletonize` замерами
     времени, чтобы понять, на что тратится время внутри нее. Для этого
     открываем ее код и обрамляем основные функции макросами `TS` и `TE`, как
     это сделано для функции `imwrite`.

  1. После этого нужно построить и запустить демо-приложение. Первое, в чем
     нужно убедиться, это что сумма времени работы отдельных функций примерно
     дает суммарное время работы алгоритма (таймер `TIMER_total` в консоли).
     Если сумма примерно равна общему времени работы алгоритма, значит вы
     знаете, где тратит свое время программа.

  1. Далее запускаем демо-приложение с и без опции `--save`. Смотрим, какую
     часть времени приложение тратило на сохранение изображений. Далее всегда
     работаем без опции `--save`, поскольку она сильно замедляет работу
     алгоритма. Это понятно, поскольку в данном случае идет работа с жестким
     диском, и она нас точно не интересует с точки зрения работы алгоритма.

  1. Затем следует проанализировать разброс в замерах времени. Для этого
     запускаем демо-приложение несколько раз и записываем например на листочке
     времена работы. Оцениваем разброс значений, хотя бы просто "на глазок".
     Потом мы сравним эти значения с теми, что дают тесты производительности.

### Анализ метрик производительности

В тестовую сборку уже включен некий тест производительности, и в этом разделе
мы научимся запускать его, сохранять метрики производительности в XML-файл, и
затем анализировать их при помощи вспомогательных скриптов.


Например так:

```bash
$ ./bin/perf_skeleton --gtest_output=xml:perf_report.xml
```

<!-- LINKS -->

[writing-perf-tests]: https://github.com/Itseez/opencv/wiki/HowToWritePerfTests
[using-perf-tests]:   https://github.com/Itseez/opencv/wiki/HowToUsePerfTests
